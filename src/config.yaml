---

checkpoint:
    save_checkpoint: True
    save_path: checkpoints/model.pth
    load_checkpoint: False
    load_path: checkpoints/model.pth

dataset:
    images_dir: C:/DocLayNet_core/PNG/
    train_labels_file: C:/DocLayNet_core/COCO/train.json
    val_labels_file: C:/DocLayNet_core/COCO/val.json
    test_labels_file: C:/DocLayNet_core/COCO/test.json
    anchors_file: data/anchors.csv
    mean_std_file: data/mean_std.json
    num_classes: 11
    image_size: 1025
    doc_categories: [] # If empty, all the categories are considered
    apply_augmentations: True

model:
    # DiT implementation uses default Detectron2 config values for the following parameters
    # See https://github.com/facebookresearch/detectron2/blob/dc9ad7055b48f25ab0a13e817c1a427b1385f98a/detectron2/config/defaults.py#L140-L154
    fpn_channels: 256
    fpn_use_batchnorm: False
    backbone: microsoft/dit-base

hyperparameters:
    optimizer: AdamW # AdamW, SGD
    epochs: 8 # ~80 minutes per epoch -> 10.5 hours for 8 epochs
    learning_rate: 2.0e-4
    weight_decay: 0.05
    momentum: 0.9
    gradient_accumulation_steps: 1 # 1 to disable
    gradient_clip:
        enabled: True
        max_grad_norm: 1.0
        grad_norm_type: 2 # Euclidean norm
    scheduler:
        enabled: True
        warmup_epochs: 1 # 0 to disable
    early_stopping:
        enabled: True
        patience: 3
        restore_best: True

test:
    checkpoint_path: checkpoints/E/model.pth
    non_max_suppression:
        min_confidence: 0.05
        min_iou: 0.45
    # map_iou_threshold: 0.5 # At the moment I compute mAP for all the IoU thresholds between 0.5 and 0.95

dataloader:
    train:
        shuffle: True
        batch_size: 8
        num_workers: 1
        pin_memory: True
        drop_last: True
    val:
        shuffle: False
        batch_size: 8
        num_workers: 1
        pin_memory: True
        drop_last: False
    test:
        shuffle: False
        batch_size: 8
        num_workers: 1
        pin_memory: True
        drop_last: False

wandb:
    enabled: True
    log_freq: 64 # number of batches between two wandb logs
    watch_model: False
    watch_model_type: 'all' # 'gradients', 'parameters', 'all', None
    project: document-layout-analysis
    entity: "iosonopersia" # user or team name
    resume_run: False
    resume_run_id: "" # wandb run id to resume

...
